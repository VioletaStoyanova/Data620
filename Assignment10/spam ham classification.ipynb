{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 11\n",
    "## Team Members: Natalie Mollaghan, Violet Stoyanova, Sudhan Maharjan\n",
    "Document Classification\n",
    "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  Here is one example of such data:  http://archive.ics.uci.edu/ml/datasets/Spambase\n",
    "\n",
    "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
    "\n",
    "For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.\n",
    "\n",
    "You may work in a small group on this project. Please include a short video with a presentation of your work. Due 4/15\n",
    "Relevant Information:\n",
    "        The \"spam\" concept is diverse: advertisements for products/web\n",
    "        sites, make money fast schemes, chain letters, pornography...\n",
    "\tOur collection of spam e-mails came from our postmaster and \n",
    "\tindividuals who had filed spam.  Our collection of non-spam \n",
    "\te-mails came from filed work and personal e-mails, and hence\n",
    "\tthe word 'george' and the area code '650' are indicators of \n",
    "\tnon-spam.  These are useful when constructing a personalized \n",
    "\tspam filter.  One would either have to blind such non-spam \n",
    "\tindicators or get a very wide collection of non-spam to \n",
    "\tgenerate a general purpose spam filter.\n",
    "\n",
    "        For background on spam:\n",
    "        Cranor, Lorrie F., LaMacchia, Brian A.  Spam! \n",
    "        Communications of the ACM, 41(8):74-83, 1998.\n",
    "\n",
    "5. Number of Instances: 4601 (1813 Spam = 39.4%)\n",
    "\n",
    "6. Number of Attributes: 58 (57 continuous, 1 nominal class label)\n",
    "\n",
    "7. Attribute Information:\n",
    "The last column of 'spambase.data' denotes whether the e-mail was \n",
    "considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \n",
    "Most of the attributes indicate whether a particular word or\n",
    "character was frequently occuring in the e-mail.  The run-length\n",
    "attributes (55-57) measure the length of sequences of consecutive \n",
    "capital letters.  For the statistical measures of each attribute, \n",
    "see the end of this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.671</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.450</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.022</td>\n",
       "      <td>9.744</td>\n",
       "      <td>445</td>\n",
       "      <td>1257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.729</td>\n",
       "      <td>43</td>\n",
       "      <td>749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9  ...    48     49  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00 ...  0.00  0.000   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94 ...  0.00  0.132   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25 ...  0.01  0.143   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.137   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.135   \n",
       "5  0.00  0.00  0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00 ...  0.00  0.223   \n",
       "6  0.00  0.00  0.00  0.0  1.92  0.00  0.00  0.00  0.00  0.64 ...  0.00  0.054   \n",
       "7  0.00  0.00  0.00  0.0  1.88  0.00  0.00  1.88  0.00  0.00 ...  0.00  0.206   \n",
       "8  0.15  0.00  0.46  0.0  0.61  0.00  0.30  0.00  0.92  0.76 ...  0.00  0.271   \n",
       "9  0.06  0.12  0.77  0.0  0.19  0.32  0.38  0.00  0.06  0.00 ...  0.04  0.030   \n",
       "\n",
       "    50     51     52     53     54   55    56  57  \n",
       "0  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "5  0.0  0.000  0.000  0.000  3.000   15    54   1  \n",
       "6  0.0  0.164  0.054  0.000  1.671    4   112   1  \n",
       "7  0.0  0.000  0.000  0.000  2.450   11    49   1  \n",
       "8  0.0  0.181  0.203  0.022  9.744  445  1257   1  \n",
       "9  0.0  0.244  0.081  0.000  1.729   43   749   1  \n",
       "\n",
       "[10 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/maharjansudhan/DATA620/master/spambase.data',header=None)\n",
    "data.shape\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the column names are missing and we'll refer to the attribute information to rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "13    float64\n",
      "14    float64\n",
      "15    float64\n",
      "16    float64\n",
      "17    float64\n",
      "18    float64\n",
      "19    float64\n",
      "20    float64\n",
      "21    float64\n",
      "22    float64\n",
      "23    float64\n",
      "24    float64\n",
      "25    float64\n",
      "26    float64\n",
      "27    float64\n",
      "28    float64\n",
      "29    float64\n",
      "30    float64\n",
      "31    float64\n",
      "32    float64\n",
      "33    float64\n",
      "34    float64\n",
      "35    float64\n",
      "36    float64\n",
      "37    float64\n",
      "38    float64\n",
      "39    float64\n",
      "40    float64\n",
      "41    float64\n",
      "42    float64\n",
      "43    float64\n",
      "44    float64\n",
      "45    float64\n",
      "46    float64\n",
      "47    float64\n",
      "48    float64\n",
      "49    float64\n",
      "50    float64\n",
      "51    float64\n",
      "52    float64\n",
      "53    float64\n",
      "54    float64\n",
      "55      int64\n",
      "56      int64\n",
      "57      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Variable types\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.104553     0.213015     0.280656     0.065425     0.312223   \n",
       "std       0.305358     1.290575     0.504143     1.395151     0.672513   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.420000     0.000000     0.380000   \n",
       "max       4.540000    14.280000     5.100000    42.810000    10.000000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.095901     0.114208     0.105295     0.090067     0.239413   \n",
       "std       0.273824     0.391441     0.401071     0.278616     0.644755   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.160000   \n",
       "max       5.880000     7.270000    11.110000     5.260000    18.180000   \n",
       "\n",
       "          ...                48           49           50           51  \\\n",
       "count     ...       4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      ...          0.038575     0.139030     0.016976     0.269071   \n",
       "std       ...          0.243471     0.270355     0.109394     0.815672   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.065000     0.000000     0.000000   \n",
       "75%       ...          0.000000     0.188000     0.000000     0.315000   \n",
       "max       ...          4.385000     9.752000     4.081000    32.478000   \n",
       "\n",
       "                52           53           54           55            56  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000   4601.000000   \n",
       "mean      0.075811     0.044238     5.191515    52.172789    283.289285   \n",
       "std       0.245882     0.429342    31.729449   194.891310    606.347851   \n",
       "min       0.000000     0.000000     1.000000     1.000000      1.000000   \n",
       "25%       0.000000     0.000000     1.588000     6.000000     35.000000   \n",
       "50%       0.000000     0.000000     2.276000    15.000000     95.000000   \n",
       "75%       0.052000     0.000000     3.706000    43.000000    266.000000   \n",
       "max       6.003000    19.829000  1102.500000  9989.000000  15841.000000   \n",
       "\n",
       "                57  \n",
       "count  4601.000000  \n",
       "mean      0.394045  \n",
       "std       0.488698  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the columns\n",
    "data.columns=['word_freq_make','word_freq_address','word_freq_all','word_freq_3d','word_freq_our','word_freq_over',\n",
    "              'word_freq_remove','word_freq_internet','word_freq_order','word_freq_mail','word_freq_receive',\n",
    "              'word_freq_will','word_freq_people','word_freq_report','word_freq_addresses','word_freq_free',\n",
    "              'word_freq_business','word_freq_email','word_freq_you','word_freq_credit','word_freq_your',\n",
    "              'word_freq_font','word_freq_000','word_freq_money','word_freq_hp','word_freq_hpl','word_freq_george',\n",
    "              'word_freq_650','word_freq_lab','word_freq_labs','word_freq_telnet','word_freq_857','word_freq_data',\n",
    "              'word_freq_415','word_freq_85','word_freq_technology','word_freq_1999','word_freq_parts','word_freq_pm',\n",
    "              'word_freq_direct','word_freq_cs','word_freq_meeting','word_freq_original','word_freq_project',\n",
    "              'word_freq_re','word_freq_edu','word_freq_table','word_freq_conference','char_freq_;','char_freq_(',\n",
    "              'char_freq_[','char_freq_!','char_freq_$','char_freq_#','capital_run_length_average','capital_run_length_longest',\n",
    "              'capital_run_length_total','spamclass']                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spamclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.671</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.450</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.022</td>\n",
       "      <td>9.744</td>\n",
       "      <td>445</td>\n",
       "      <td>1257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.729</td>\n",
       "      <td>43</td>\n",
       "      <td>749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "5            0.00               0.00           0.00           0.0   \n",
       "6            0.00               0.00           0.00           0.0   \n",
       "7            0.00               0.00           0.00           0.0   \n",
       "8            0.15               0.00           0.46           0.0   \n",
       "9            0.06               0.12           0.77           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "5           1.85            0.00              0.00                1.85   \n",
       "6           1.92            0.00              0.00                0.00   \n",
       "7           1.88            0.00              0.00                1.88   \n",
       "8           0.61            0.00              0.30                0.00   \n",
       "9           0.19            0.32              0.38                0.00   \n",
       "\n",
       "   word_freq_order  word_freq_mail    ...      char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00    ...             0.00        0.000   \n",
       "1             0.00            0.94    ...             0.00        0.132   \n",
       "2             0.64            0.25    ...             0.01        0.143   \n",
       "3             0.31            0.63    ...             0.00        0.137   \n",
       "4             0.31            0.63    ...             0.00        0.135   \n",
       "5             0.00            0.00    ...             0.00        0.223   \n",
       "6             0.00            0.64    ...             0.00        0.054   \n",
       "7             0.00            0.00    ...             0.00        0.206   \n",
       "8             0.92            0.76    ...             0.00        0.271   \n",
       "9             0.06            0.00    ...             0.04        0.030   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "5          0.0        0.000        0.000        0.000   \n",
       "6          0.0        0.164        0.054        0.000   \n",
       "7          0.0        0.000        0.000        0.000   \n",
       "8          0.0        0.181        0.203        0.022   \n",
       "9          0.0        0.244        0.081        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "5                       3.000                          15   \n",
       "6                       1.671                           4   \n",
       "7                       2.450                          11   \n",
       "8                       9.744                         445   \n",
       "9                       1.729                          43   \n",
       "\n",
       "   capital_run_length_total  spamclass  \n",
       "0                       278          1  \n",
       "1                      1028          1  \n",
       "2                      2259          1  \n",
       "3                       191          1  \n",
       "4                       191          1  \n",
       "5                        54          1  \n",
       "6                       112          1  \n",
       "7                        49          1  \n",
       "8                      1257          1  \n",
       "9                       749          1  \n",
       "\n",
       "[10 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Violet\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b0dc4ee048>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.barplot(x=\"spamclass\", y=\"capital_run_length_total\", data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the barplot, we can say that there are more non spam emails than spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam: 1813\n",
      "Not spam: 2788\n"
     ]
    }
   ],
   "source": [
    "# Count the number of spam vs. not spam\n",
    "c1 = len(data[data.spamclass==1])\n",
    "c0 = len(data[data.spamclass==0])\n",
    "\n",
    "print(\"Spam: %d\" %c1)\n",
    "print(\"Not spam: %d\" %c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into test, train, and validate\n",
    "percTrain = 0.7\n",
    "percVal = 0.15\n",
    "percTest = 0.15\n",
    "\n",
    "N = len(data)\n",
    "trainNum = int(percTrain * N)\n",
    "valNum = int(percVal * N)\n",
    "testNum = N - trainNum - valNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target: 3220\n",
      "Validation target: 690\n",
      "Testing target: 691\n",
      "Total: 4601\n"
     ]
    }
   ],
   "source": [
    "# Check targets\n",
    "print(\"Training target: %d\" %trainNum)\n",
    "print (\"Validation target: %d\" %valNum)\n",
    "print (\"Testing target: %d\" %testNum)\n",
    "print (\"Total: %d\" %(trainNum + valNum + testNum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainSet, testSet = train_test_split(data, test_size=testNum, random_state=8)\n",
    "trainSet, valSet = train_test_split(trainSet, test_size=valNum, random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 3220\n",
      "Validation set: 690\n",
      "Testing set: 691\n",
      "Total: 4601\n"
     ]
    }
   ],
   "source": [
    "# Check lengths\n",
    "print(\"Training set: %d\" %len(trainSet))\n",
    "print(\"Validation set: %d\" %len(valSet))\n",
    "print(\"Testing set: %d\" %len(testSet))\n",
    "print (\"Total: %d\" %(len(trainSet) + len(valSet) + len(testSet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree \n",
    "\n",
    "## Advantages:\n",
    "Decision Trees are easy to explain. It results in a set of rules.\n",
    "It follows the same approach as humans generally follow while making decisions.\n",
    "Interpretation of a complex Decision Tree model can be simplified by its visualizations. Even a naive person can understand logic.\n",
    "The Number of hyper-parameters to be tuned is almost null.\n",
    "## Disadvantages:\n",
    "There is a high probability of overfitting in Decision Tree.\n",
    "Generally, it gives low prediction accuracy for a dataset as compared to other machine learning algorithms.\n",
    "Information gain in a decision tree with categorical variables gives a biased response for attributes with greater no. of categories.\n",
    "Calculations can become complex when there are many class labels\n",
    "\n",
    "From: http://dataaspirant.com/2017/01/30/how-decision-tree-algorithm-works/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "from sklearn import tree\n",
    "import sklearn.metrics as sm\n",
    "\n",
    "# Train classifier\n",
    "trainSetClass = trainSet['spamclass']\n",
    "trainSetVars = trainSet.drop(labels='spamclass', axis=1)\n",
    "dt = tree.DecisionTreeClassifier(criterion=\"entropy\", random_state=88)\n",
    "dt_fit = dt.fit(trainSetVars, trainSetClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_summary(actual, pred):\n",
    "    cm = sm.confusion_matrix(actual, pred, labels=[1, 0])\n",
    "    print(\"True positives: %d\" %cm[0,0])\n",
    "    print (\"False positives: %d\" %cm[1,0])\n",
    "    print (\"True negatives: %d\" %cm[1,1])\n",
    "    print (\"False negatives: %d\" %cm[0,1])\n",
    "    print\n",
    "    print (sm.classification_report(actual, pred, labels=[1,0], target_names=[\"Spam\", \"Not spam\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives: 1260\n",
      "False positives: 0\n",
      "True negatives: 1958\n",
      "False negatives: 2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Spam       1.00      1.00      1.00      1262\n",
      "   Not spam       1.00      1.00      1.00      1958\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training performance\n",
    "dt_train = dt_fit.predict(trainSetVars)\n",
    "model_summary(trainSetClass, dt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives: 252\n",
      "False positives: 17\n",
      "True negatives: 401\n",
      "False negatives: 20\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Spam       0.94      0.93      0.93       272\n",
      "   Not spam       0.95      0.96      0.96       418\n",
      "\n",
      "avg / total       0.95      0.95      0.95       690\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision tree - validation set\n",
    "valSetClass = valSet['spamclass']\n",
    "valSetVars = valSet.drop(labels='spamclass', axis=1)\n",
    "\n",
    "dt_val = dt_fit.predict(valSetVars)\n",
    "model_summary(valSetClass, dt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives: 251\n",
      "False positives: 29\n",
      "True negatives: 383\n",
      "False negatives: 28\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Spam       0.90      0.90      0.90       279\n",
      "   Not spam       0.93      0.93      0.93       412\n",
      "\n",
      "avg / total       0.92      0.92      0.92       691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision tree - test set\n",
    "testSetClass = testSet['spamclass']\n",
    "testSetVars = testSet.drop(labels='spamclass', axis=1)\n",
    "\n",
    "dt_test = dt_fit.predict(testSetVars)\n",
    "model_summary(testSetClass, dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var</th>\n",
       "      <th>Imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>char_freq_!</td>\n",
       "      <td>0.296289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>char_freq_$</td>\n",
       "      <td>0.130370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>word_freq_remove</td>\n",
       "      <td>0.125547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>capital_run_length_average</td>\n",
       "      <td>0.056054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>capital_run_length_longest</td>\n",
       "      <td>0.035736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>word_freq_george</td>\n",
       "      <td>0.033155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>capital_run_length_total</td>\n",
       "      <td>0.026242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>word_freq_hp</td>\n",
       "      <td>0.025670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word_freq_our</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>word_freq_you</td>\n",
       "      <td>0.024984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Var       Imp\n",
       "51                 char_freq_!  0.296289\n",
       "52                 char_freq_$  0.130370\n",
       "6             word_freq_remove  0.125547\n",
       "54  capital_run_length_average  0.056054\n",
       "55  capital_run_length_longest  0.035736\n",
       "26            word_freq_george  0.033155\n",
       "56    capital_run_length_total  0.026242\n",
       "24                word_freq_hp  0.025670\n",
       "4                word_freq_our  0.025391\n",
       "18               word_freq_you  0.024984"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature importance\n",
    "def featImp(modelfit, setVars): \n",
    "    featFit = modelfit.feature_importances_\n",
    "    df = {'Var': pd.Series(setVars.columns.values), 'Imp': pd.Series(featFit)}\n",
    "    fi = pd.DataFrame(df, columns=['Var','Imp'])\n",
    "    return fi.sort_values(['Imp'], ascending=0).head(10)\n",
    "    \n",
    "\n",
    "featImp(dt_fit, testSetVars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest Model\n",
    "\n",
    "\"A random forest is simply a collection of decision trees whose results are aggregated into one final result. Their ability to limit overfitting without substantially increasing error due to bias is why they are such powerful models.\"\n",
    "From: https://towardsdatascience.com/decision-trees-and-random-forests-df0c3123f991"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest classifier creates a set of decision trees from randomly selected subset of training set. It then aggregates the votes from different decision trees to decide the final class of the test object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Violet\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spamclass are the values we want to predict\n",
    "spamclass = np.array(data['spamclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the spamclass from the data\n",
    "# axis 1 refers to the columns\n",
    "data= data.drop('spamclass', axis = 1)\n",
    "\n",
    "# Saving data names for later use\n",
    "data_list = list(data.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "training_data, testing_data, training_spamclass, testing_spamclass = train_test_split(data, spamclass, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (3450, 57)\n",
      "Training Spam Shape: (3450,)\n",
      "Testing Data Shape: (1151, 57)\n",
      "Testing Spam Shape: (1151,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Data Shape:', training_data.shape)\n",
    "print('Training Spam Shape:', training_spamclass.shape)\n",
    "print('Testing Data Shape:', testing_data.shape)\n",
    "print('Testing Spam Shape:', testing_spamclass.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model creation\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "rfc.fit(training_data,training_spamclass)\n",
    "\n",
    "# predictions\n",
    "rfc_predict = rfc.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_cv_score = cross_val_score(rfc, data, spamclass, cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[662  14]\n",
      " [ 51 424]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95       676\n",
      "          1       0.97      0.89      0.93       475\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1151\n",
      "\n",
      "\n",
      "\n",
      "All AUC Scores\n",
      "[0.97631848 0.96087873 0.96585135 0.98231648 0.99007901 0.97569259\n",
      " 0.99507911 0.98797996 0.96135578 0.93081005]\n",
      "\n",
      "\n",
      "Mean AUC Score\n",
      "Mean AUC Score - Random Forest:  0.9726361541118399\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(testing_spamclass, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(testing_spamclass, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"All AUC Scores\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"Mean AUC Score\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 10.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 260}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# number of features at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# max depth\n",
    "max_depth = [int(x) for x in np.linspace(100, 500, num = 11)]\n",
    "max_depth.append(None)\n",
    "# create random grid\n",
    "random_grid = {\n",
    " 'n_estimators': n_estimators,\n",
    " 'max_features': max_features,\n",
    " 'max_depth': max_depth\n",
    " }\n",
    "# Random search of parameters\n",
    "rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the model\n",
    "rfc_random.fit(training_data, training_spamclass)\n",
    "# print results\n",
    "print(rfc_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[662  14]\n",
      " [ 34 441]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97       676\n",
      "          1       0.97      0.93      0.95       475\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1151\n",
      "\n",
      "\n",
      "\n",
      "All AUC Scores\n",
      "[0.98916854 0.96645201 0.97325613 0.98725717 0.99298006 0.9875047\n",
      " 0.99678211 0.99473257 0.96611551 0.92616956]\n",
      "\n",
      "\n",
      "Mean AUC Score\n",
      "Mean AUC Score - Random Forest:  0.9780418364793674\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=1200, max_depth=100, max_features='sqrt')\n",
    "rfc.fit(training_data,training_spamclass)\n",
    "rfc_predict = rfc.predict(testing_data)\n",
    "rfc_cv_score = cross_val_score(rfc, data, spamclass, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(testing_spamclass, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(testing_spamclass, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"All AUC Scores\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"Mean AUC Score\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var</th>\n",
       "      <th>Imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>char_freq_!</td>\n",
       "      <td>0.113850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>char_freq_$</td>\n",
       "      <td>0.095123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>word_freq_remove</td>\n",
       "      <td>0.081537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>word_freq_free</td>\n",
       "      <td>0.070802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>capital_run_length_average</td>\n",
       "      <td>0.063214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>word_freq_your</td>\n",
       "      <td>0.060098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>capital_run_length_longest</td>\n",
       "      <td>0.058759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>capital_run_length_total</td>\n",
       "      <td>0.044816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>word_freq_hp</td>\n",
       "      <td>0.041358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>word_freq_money</td>\n",
       "      <td>0.031723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Var       Imp\n",
       "51                 char_freq_!  0.113850\n",
       "52                 char_freq_$  0.095123\n",
       "6             word_freq_remove  0.081537\n",
       "15              word_freq_free  0.070802\n",
       "54  capital_run_length_average  0.063214\n",
       "20              word_freq_your  0.060098\n",
       "55  capital_run_length_longest  0.058759\n",
       "56    capital_run_length_total  0.044816\n",
       "24                word_freq_hp  0.041358\n",
       "23             word_freq_money  0.031723"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature importance\n",
    "def featImp(fit, setVars): \n",
    "    featFit = rfc.feature_importances_\n",
    "    df = {'Var': pd.Series(data_list), 'Imp': pd.Series(featFit)}\n",
    "    fi = pd.DataFrame(df, columns=['Var','Imp'])\n",
    "    return fi.sort_values(['Imp'], ascending=0).head(10)\n",
    "    \n",
    "\n",
    "featImp(rfc.fit, data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)\n",
    "\n",
    "The main reason to use an SVM instead is because the problem might not be linearly separable. In that case, we will have to use an SVM with a non linear kernel (e.g. RBF).\n",
    "\n",
    "Another related reason to use SVMs is if you are in a highly dimensional space. For example, SVMs have been reported to work better for text classification.\n",
    "\n",
    "But it requires a lot of time for training. So, it is not recommended when we have a large number of training examples.\n",
    "From: https://discuss.analyticsvidhya.com/t/which-one-to-use-randomforest-vs-svm-vs-knn/2897/3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives: 1126\n",
      "False positives: 52\n",
      "True negatives: 1906\n",
      "False negatives: 136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Spam       0.96      0.89      0.92      1262\n",
      "   Not spam       0.93      0.97      0.95      1958\n",
      "\n",
      "avg / total       0.94      0.94      0.94      3220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM - train\n",
    "from sklearn import svm\n",
    "\n",
    "sv = svm.SVC(random_state=88)\n",
    "sv_fit = sv.fit(trainSetVars, trainSetClass)\n",
    "\n",
    "sv_train = sv_fit.predict(trainSetVars)\n",
    "model_summary(trainSetClass, sv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives: 214\n",
      "False positives: 61\n",
      "True negatives: 351\n",
      "False negatives: 65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Spam       0.78      0.77      0.77       279\n",
      "   Not spam       0.84      0.85      0.85       412\n",
      "\n",
      "avg / total       0.82      0.82      0.82       691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM - test set\n",
    "sv_test = sv_fit.predict(testSetVars)\n",
    "model_summary(testSetClass, sv_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "One can see that all three algorithms performed well, especially Random Forest with 94% accuracy followed by Decision Tree and SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
